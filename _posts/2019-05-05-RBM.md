---
layout: single
title:  "RBM Deep Dive with Tensorflow (KR)"
header:
  teaser: "images/syleeie/2019-05-05/rbm_header.png"
  overlay_color: "#000"
  overlay_filter: "0.5"
  overlay_image: images/syleeie/2019-05-05/rbm_2.jpg
  caption: "Photo credit: [**Unsplash**](https://unsplash.com)"
excerpt: "ì˜¤ëŠ˜ ë¦¬ë·°í•  ì½”ë“œëŠ” ë§ˆì´í¬ë¡œì†Œí”„íŠ¸ Recommenders ê¹ƒí—™ì— ìˆëŠ” Restricted Boltzmann Machines (RBM)ì…ë‹ˆë‹¤."    
categories: 
  - Code Review
tags:
  - RBM
  - Tensorflow
author: syleeie

toc: true
toc_label: "ëª©ì°¨"
toc_icon: "cog"
---


<i>Copyright (c) Microsoft Corporation. All rights reserved.</i>

<i>Licensed under the MIT License.</i>

# RBM Deep Dive with Tensorflow 

- jupyter notebookì—ì„œëŠ” ì¶”ì²œ ì‹œìŠ¤í…œì— ëŒ€í•œ ì‘ìš© í”„ë¡œê·¸ë¨ê³¼ í•¨ê»˜ ì œí•œëœ ë³¼ì¸ ë§Œ ì»´í“¨í„° (RBM) ì•Œê³ ë¦¬ì¦˜ì˜ ì „ì²´ ì—°ìŠµì„ ì œê³µí•©ë‹ˆë‹¤. 
- íŠ¹íˆ, ìš°ë¦¬ëŠ” 1ì—ì„œ 5ê¹Œì§€ì˜ ë“±ê¸‰ìœ¼ë¡œ ì˜í™” ìˆœìœ„ë¥¼ êµ¬ì„±í•˜ëŠ” ì´í„° ì„¸íŠ¸ë¥¼ ì‚¬ë¡€ ì—°êµ¬ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.

[towards data science ì°¸ê³ ìë£Œ](https://towardsdatascience.com/deep-learning-meets-physics-restricted-boltzmann-machines-part-i-6df5c4918c15)


### ê°œìš”
- Restricted Boltzmann Machine (RBM)ì€ ì¼ë°˜ì ìœ¼ë¡œ unsupervised learningì„ ìˆ˜í–‰í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” generative neural network ëª¨ë¸ì…ë‹ˆë‹¤. 
- RBMì˜ ì£¼ëœ ì„ë¬´ëŠ” joint í™•ë¥  ë¶„í¬ ğ‘ƒ (ğ‘£, â„)ë¥¼ ë°°ìš°ëŠ” ê²ƒì…ë‹ˆë‹¤. ì—¬ê¸°ì„œ ğ‘£ëŠ” ë³´ì´ëŠ” ë‹¨ìœ„ì´ê³  â„ëŠ” ìˆ¨ê²¨ì§„ ë‹¨ìœ„ì…ë‹ˆë‹¤. ìˆ¨ê²¨ì§„ ìœ ë‹›ì€ latent ë³€ìˆ˜ë¥¼ ë‚˜íƒ€ë‚´ì§€ë§Œ ë³´ì´ëŠ” ìœ ë‹›ì€ ì…ë ¥ ë°ì´í„°ì— ì¡°ì¸ë©ë‹ˆë‹¤.  joint distributionê°€ í•™ìŠµë˜ë©´ ìƒ˜í”Œë§ì„ í†µí•´ ìƒˆë¡œìš´ ì˜ˆì œê°€ ìƒì„±ë©ë‹ˆë‹¤.

- ì—¬ê¸°ì„œ ì œì‹œëœ êµ¬í˜„ì€ Ruslan Salakhutdinov, Andriy Mnih ë° Geoffrey Hintonì´ ê³µë™ìœ¼ë¡œ í•„í„°ë§ì„ ì œí•œí•œ Boltzmann ì‹œìŠ¤í…œì„ ê¸°ë°˜ìœ¼ë¡œ í•¨. ë‹¨, ë…¼ë¬¸ì—ì„œ ì‚¬ìš©ëœ one-hot ì¸ì½”ë”© ëŒ€ì‹  multinomial unitsë¥¼ ì‚¬ìš©í•¨


### Advantages of RBM: 

- ëª¨ë¸ì€ í˜‘ì—… í•„í„°ë§ ê¸°ë°˜ ì ‘ê·¼ ë°©ì‹ì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì / ì˜í™” ìŒì— ëŒ€í•œ ë“±ê¸‰ì„ ìƒì„±í•©ë‹ˆë‹¤. í–‰ë ¬ ì¸ìˆ˜ë¶„í•´ ë°©ë²•ì€ User / Item affinity matrix(ìœ ì‚¬ë„ ë§¤íŠ¸ë¦­ìŠ¤)ì˜ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì¬í˜„í•˜ëŠ” ë°©ë²•ì„ ë°°ìš°ëŠ” ë°˜ë©´, RBMì€ ê¸°ë³¸ í™•ë¥  ë¶„í¬ë¥¼ ë°°ì›ë‹ˆë‹¤. ì—¬ê¸°ì—ëŠ” ëª‡ ê°€ì§€ ì¥ì ì´ ìˆìŠµë‹ˆë‹¤.

- ì¼ë°˜í™” ê°€ëŠ¥ì„±
    - ëª¨ë¸ì€ í™•ë¥ ì´ í¬ê²Œ ë‹¤ë¥´ì§€ ì•Šì€ í•œ ìƒˆë¡œìš´ ì˜ˆì œë¡œ ì¼ë°˜í™”ë¨
- ì‹œê°„ì˜ ì•ˆì •ì„±
    - ì¶”ì²œ ì‘ì—…ì´ ì‹œê°„ ê³ ì •ì¸ ê²½ìš° ëª¨ë¸ì€ ìƒˆë¡œìš´ ë“±ê¸‰ / ì‚¬ìš©ìë¥¼ ìˆ˜ìš©í•˜ê¸° ìœ„í•´ ìì£¼ í›ˆë ¨í•  í•„ìš”ê°€ ì—†ìŒ

- ì—¬ê¸°ì— ì œì‹œëœ í…ì„œí”Œë¡œìš° êµ¬í˜„ì„ í†µí•´ GPUì— ëŒ€í•œ ë¹ ë¥´ê³  í™•ì¥ ê°€ëŠ¥í•œ í›ˆë ¨ì„ í—ˆìš©

#### 1. RBM ì´ë¡ 
#### 2. í…ì„œí”Œë¡œìš° êµ¬í˜„ ë° ëª¨ë¸ ë§¤ê°œë³€ìˆ˜
#### 3. ë°ì´í„° ì¤€ë¹„ ë° ê²€ì‚¬
#### 4. ëª¨ë¸ ì‘ìš©, ì„±ëŠ¥ ë° ë¶„ì„

- ì„¹ì…˜ 1ì ˆê³¼ 2ì ˆì€ ì„ í˜• ëŒ€ìˆ˜í•™, í™•ë¥  ì´ë¡  ë° í…ì„œ í”Œë¡œìš°ì— ëŒ€í•œ ê¸°ë³¸ ì§€ì‹ì´ í•„ìš”í•©ë‹ˆë‹¤.
- ì„¹ì…˜ 3ì ˆê³¼ 4ì ˆì€ ê¸°ë³¸ì ì¸ ë°ì´í„° ê³¼í•™ ì´í•´ë§Œ í•„ìš”ë¡œ í•¨. ë‹¹ì‹ ì´ ê°€ì¥ ê´€ì‹¬ ìˆëŠ” êµ¬ì—­ìœ¼ë¡œ ë›°ì–´ê°€ë„ ì¢‹ë‹¤!

## 0 Global Settings and Import


```python
from __future__ import print_function
from __future__ import absolute_import
from __future__ import division

# set the environment path to find Recommenders
import sys
sys.path.append("../../")

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib inline

import papermill 

#RBM 
from reco_utils.recommender.rbm.rbm import RBM
from reco_utils.dataset.python_splitters import numpy_stratified_split
from reco_utils.dataset.sparse import AffinityMatrix

#Evaluation libraries
from reco_utils.dataset import movielens 

from reco_utils.evaluation.python_evaluation import (
    map_at_k,
    ndcg_at_k,
    precision_at_k,
    recall_at_k,
)

from reco_utils.evaluation.parameter_sweep import generate_param_grid
#For interactive mode only
%load_ext autoreload
%autoreload 2

print("System version: {}".format(sys.version))
print("Pandas version: {}".format(pd.__version__))
```

    System version: 3.5.2 (default, Nov 12 2018, 13:43:14) 
    [GCC 5.4.0 20160609]
    Pandas version: 0.23.4


## 1. RBM Theory 

## 1.1 Overview and main differences with other recommender algorithms

- ì œí•œëœ ë³¼ì¸ ë§Œ ê¸°ê³„(RBM)ëŠ” ì›ë˜ magnetic systems(ìì„ì‹??)ì˜ í†µê³„ ì—­í•™(ë˜ëŠ” ë¬¼ë¦¬í•™)ì„ ì—°êµ¬í•˜ê¸° ìœ„í•´ ê³ ì•ˆëœ undirected graphical modelì´ë‹¤. 

![](https://cdn-images-1.medium.com/max/1600/1*_7GZ3WAtplfzE73AgB_NbA.png)

- í†µê³„ì—­í•™ (Statistical mechanics)ì€ ì—„ì²­ë‚œ ìˆ˜ì˜ êµ¬ì„± ìš”ì†Œ (ì¼ë°˜ì ìœ¼ë¡œ ~1023)ë¡œ êµ¬ì„±ëœ ë³µì¡í•œ ì‹œìŠ¤í…œì— ëŒ€í•œ í™•ë¥ ë¡ ì  ì„¤ëª…ì„ ì œê³µí•©ë‹ˆë‹¤. ì‹œìŠ¤í…œì˜ íŠ¹ì • ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë³´ëŠ” ëŒ€ì‹  SMì˜ ëª©ì ì€ ì¼ë°˜ì ì¸ ë™ì‘ì„ ì„¤ëª…í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. 

- ì´ ì ‘ê·¼ë²•ì€ ê°€ìŠ¤, ì•¡ì²´, ë³µí•© ì¬ë£Œ (ì˜ˆ :. ë°˜ë„ì²´) ê·¸ë¦¬ê³  ìœ ëª…í•œ í‰ìŠ¤ ì…ì! ([í‰ìŠ¤ì…ì](https://terms.naver.com/entry.nhn?docId=1532312&cid=40942&categoryId=32245))


- ë§ì€ ì–‘ì˜ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ê³  êµ¬ì„±í•˜ë„ë¡ ì„¤ê³„ëœ SMì€ í˜„ëŒ€ í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ì—ì„œ ì´ìƒì ì¸ ì‘ìš© í”„ë¡œê·¸ë¨ì„ ì°¾ìŠµë‹ˆë‹¤. 
- ì¶”ì²œ ì‹œìŠ¤í…œì˜ ë§¥ë½ì—ì„œ ì•„ì´ë””ì–´ëŠ” íŠ¹ì • ì¸ìŠ¤í„´ìŠ¤ ëŒ€ì‹  ì¼ë°˜ì ì¸ ì‚¬ìš©ì ë™ì‘ì„ ë°°ìš°ëŠ” ê²ƒì…ë‹ˆë‹¤. 
- ë” ì˜ ì´í•´í•˜ê¸° ìœ„í•´ ì¶”ì²œì‹œìŠ¤í…œ ë¬¸ì œì˜ ê°€ì¥ ì¼ë°˜ì ì¸ ì„¤ì •ì„ ê³ ë ¤í•˜ì‹­ì‹œì˜¤. ì¼ë¶€ ì²™ë„ì— ë”°ë¼ n í•­ëª©ì„ í‰ê°€í•˜ëŠ” m ì‚¬ìš©ìê°€ ìˆìŠµë‹ˆë‹¤ (ì˜ˆ : 1ì—ì„œ 5ê¹Œì§€)
    - ì˜¨ë¼ì¸ ì‡¼í•‘, ìŠ¤íŠ¸ë¦¬ë° ì„œë¹„ìŠ¤ ë˜ëŠ” ì˜ì‚¬ê²°ì • í”„ë¡œì„¸ìŠ¤ì˜ ì¼ë°˜ì ì¸ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì‚¬ìš©ìëŠ” ì œí’ˆì˜ í•˜ìœ„ ì§‘í•© l << më§Œ í‰ê°€í•©ë‹ˆë‹¤.
    - ì´ ë¬¸ì œì— ëŒ€í•œ í–‰ë ¬ í‘œí˜„ì„ ë§Œë“¤ë©´ ì‚¬ìš©ì / í•­ëª© ìœ ì‚¬ë„ í–‰ë ¬ Xë¥¼ ì–»ìŠµë‹ˆë‹¤. ë” ì½ì„ ìˆ˜ ìˆëŠ” í…Œì´ë¸” í˜•ì‹ì—ì„œ XëŠ” ë‹¤ìŒê³¼ ê°™ì´ ë³´ì…ë‹ˆë‹¤.


|  $X$   |$i_1$  |$i_2$  |$i_3$  |  ... |$i_m$  | 
|-----|-------|-------|-------|------|-------|
|$u_1$|5      |0      |2      |0 ... |1      |
|$u_2$|0      |0      |3      |4 ... |0      |
|...  |...    |...    |...    |...   |...    |
|$u_m$|3      |3      |0      |5...  |2      |

- ì—¬ê¸°ì„œ 0ì€ ë“±ê¸‰ì´ ë§¤ê²¨ì§€ì§€ ì•Šì€ í•­ëª©ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ê°„ë‹¨íˆ ë§í•´ì„œ ì¶”ì²œì˜ ì„ë¬´ëŠ” ëˆ„ë½ëœ ë“±ê¸‰ì„ "ì±„ìš°ëŠ” ê²ƒ"
    - ì´ ë¬¸ì œì— ëŒ€í•œ ê³ ì „ì ì¸ ì ‘ê·¼ ë°©ì‹ì„ í–‰ë ¬ ì¸ìˆ˜ ë¶„í•´ë¼ê³ í•©ë‹ˆë‹¤. ê¸°ë³¸ ì•„ì´ë””ì–´ëŠ” ì‚¬ìš©ì ë° í•­ëª© í–‰ë ¬ë¡œ ë¶„í•´í•˜ëŠ” ê²ƒ (f ì ì¬ ìš”ì¸ìˆ˜)
    - ì˜í™”ì˜ ì¥ë¥´, ìŒì‹ ìœ í˜• ë“± ... ê·¸ë¦¬ê³  ëª¨ë¸ì˜ í•˜ì´í¼ ë§¤ê°œ ë³€ìˆ˜ì…ë‹ˆë‹¤. 
    - ì‚¬ìš©ì í–‰ë ¬ Qì™€ ì•„ì´í…œ í–‰ë ¬ Pë¥¼ í•™ìŠµí•¨ìœ¼ë¡œì¨ X (ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ë¡œ ì œê³µ)ì˜ íŠ¹ì • ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì¬í˜„í•˜ê³  ì´ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ ëˆ„ë½ëœ í–‰ë ¬ ìš”ì†Œë¥¼ ì±„ìš°ë ¤ê³  í•¨


- RBM ì ‘ê·¼ë²•ì€ ë³´ë‹¤ ì¼ë°˜ì ì¸ í”„ë¡œì„¸ìŠ¤ì˜ íŠ¹ì • realization (ìƒ˜í”Œ)ìœ¼ë¡œ Xë¥¼ ë³´ëŠ” ê²ƒ (generative model)
    - íŠ¹ì • Xë¥¼ ë°°ìš°ëŠ” ëŒ€ì‹  Xê°€ ìƒ˜í”Œë§ëœ í–‰ë ¬ ë¶„í¬ë¥¼ ë°°ìš°ë ¤ê³  í•¨. íš¨ê³¼ì ìœ¼ë¡œ, ìš°ë¦¬ëŠ” *tastes* (i.e. latent factors) ì˜ ì „í˜•ì ì¸ ë¶„í¬ë¥¼ ë°°ì›ë‹ˆë‹¤ 
    - í•´ë‹¹ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒˆë¡œìš´ ë“±ê¸‰ì„ ìƒì„±í•©ë‹ˆë‹¤. í•´ë‹¹ ì¢…ë¥˜ì˜ ì‹ ê²½ë§ ëª¨ë¸ì€ generative ëª¨ë¸ì´ë¼ê³ ë„ í•©ë‹ˆë‹¤. 
    - ë‹¤ìŒì˜ ì˜ˆë¥¼ ìƒê°í•´ë³´ì. íŠ¹ì • êµ­ê°€ì˜ ì—°ë ¹ë³„ ì†Œë“ ë¶„ë°°ë¥¼ ê°€ì •í•˜ê³ , ë‚˜ì´ windowë¥¼ ìˆ˜ì •í•˜ì—¬ ë‹¤ì–‘í•œ ì†Œë“ì„ ê°€ì§„ ê°€ìƒ ì‹œë¯¼ì„ ì´ ì°¨ì´ì—ì„œ ì¶”ì¶œí•´ë‚¼ ìˆ˜ ìˆë‹¤.

## 1.2 Model 

- ëª¨ë“  SM ëª¨ë¸ì˜ central quantityì€ ë³¼ì¸ ë§Œ ë¶„í¬ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ í™•ë¥  ê³µê°„ì—ì„œ ê°€ì¥ í¸í–¥ëœ í™•ë¥  ë¶„í¬ë¡œ ë³¼ ìˆ˜ ìˆìœ¼ë©°, ë¶„í¬ ê³µê°„ì—ì„œ ìµœëŒ€ ì—”íŠ¸ë¡œí”¼ ì›ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì „í˜•ì ì¸ í˜•íƒœëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤ :
    - ë³¼ì¸ ë§Œ ë¶„í¬ì˜ ì¤‘ìš”í•œ ì ì€ ëª¨ë“  ì…ìë“¤ì˜ ë¯¸ì‹œì ì¸ ê³„ì‚°ì´ ì—†ì–´ë„ ê±°ì‹œì  í†µê³„ì ì¸ ë°©ë²•ì„ í†µí•´ ì „ì²´ì˜ ì¶”ì • ê°€ëŠ¥í•œ ì–‘ì„ ê³„ì‚°í•  ìˆ˜ ìˆìŒ
    - ì—ë„ˆì§€ê°€ ë‚®ì„ìˆ˜ë¡ ë§ì€ ì…ìë“¤ì´ ë¶„í¬í•™ í™•ë¥ ì´ í¬ë‹¤ëŠ” íŠ¹ì§•

$$P = \frac{1}{Z} \, e^{- \beta \, H},$$ 

- ì…ë ¥ì´ ìˆì„ í™•ë¥ ì€ ì—ë„ˆì§€(H)ì— ë°˜ë¹„ë¡€. ì—ë„ˆì§€(H)ë¥¼ í•™ìŠµí•˜ëŠ” ê²ƒì´ ëª©ì . (ì–´ë–¤ ê¸°ì²´ê°€ ê·¸ ê³µê°„ì— ì˜¨ë„ë¡œ ìˆì„ í™•ë¥ ì€ ì˜¨ë„ì—ì„œ ë‚˜ì˜¨ ì—ë„ˆì§€ì— ë°˜ë¹„ë¡€ - ì´ëŸ°ê²ƒë“¤ì´ ë³¼ì¸ ë§Œ í•´ì„ìœ¼ë¡œ ê°€ëŠ¥)

- Energy-Based Models (EBM)ì€ deep learningì—ì„œ ì…ë ¥ê³¼ ì€ë‹‰ì¸µê³¼ì˜ ê´€ê³„ë¥¼ ì—ë„ˆì§€ë¡œ í‘œí˜„í•˜ì—¬ ë³¼ì¸ ë§Œ ë¶„í¬ë¥¼ ì´ìš©í•˜ëŠ” ë°©ë²•. RBMì€ EBMì˜ ë³€í˜• (Restricted, visible ë…¸ë“œ ê°„ì˜ ê´€ê³„ ì—†ì• ê³ , hidden ë…¸ë“œ ê°„ì˜ ê´€ê³„ë¥¼ ì—†ì•¤ ê¼´)

- ZëŠ” íŒŒí‹°ì…˜ í•¨ìˆ˜ë¡œ ì•Œë ¤ì§„ ì •ê·œí™” ìƒìˆ˜(í™•ë¥ ì˜ ì´í•©ì´ 1ì„ ë§ì¶”ë„ë¡, ëª¨ë“  x,h caseì— í•´ë‹¹í•˜ëŠ” expì˜ í•©)ì´ë©°, ì—­ ì—ë„ˆì§€ ë‹¨ìœ„ë¥¼ ê°–ëŠ” noise ë§¤ê°œ ë³€ìˆ˜ì´ê³  HëŠ” ì‹œìŠ¤í…œì˜ í•´ë°€í„´ ë˜ëŠ” ì—ë„ˆì§€ í•¨ìˆ˜
- ëª¨ë¸ í´ë˜ìŠ¤ëŠ” ì»´í“¨í„° ê³¼í•™ì— ê¸°ë°˜í•œ ì—ë„ˆì§€ë¼ê³ ë„ í•¨. ë¬¼ë¦¬í•™ì—ì„œ ë³¼ì¸ ë§Œ ìƒìˆ˜ì˜ ë‹¨ìœ„ë¡œ ì‹œìŠ¤í…œì˜ ì—­ ì˜¨ë„ì´ì§€ë§Œ, H ë‚´ë¶€ì—ì„œ íš¨ê³¼ì ìœ¼ë¡œ ê·¸ê²ƒì„ ì¬ì¡°ì •í•˜ì—¬ ìˆœìˆ˜í•œ ìˆ«ìê°€ ë˜ë„ë¡ í•¨
    - ì…ë ¥ê³¼ ì¶œë ¥ì´ ì–‘ì˜ ìƒê´€ê´€ê³„ê°€ ìˆì„ìˆ˜ë¡ ì—ë„ˆì§€ê°€ ì‘ì•„ì§ (ì…ë ¥ì´ -1ì¼ ë•Œ ì€ë‹‰ì¸µ ê²°ê³¼ê°€ -1ì´ë©´ ì—ë„ˆì§€ê°€ ìµœì†Œê°€ ë¨)

![](https://cdn-images-1.medium.com/max/1000/1*Iq2Tn7aLAegiIg4sfkSgGA.png)

- HëŠ” ì¼ë°˜ì ìœ¼ë¡œ v (visibles)ì™€ h (hidden)ë¼ê³  ë¶ˆë¦¬ëŠ” ë‘ ì„¸íŠ¸ì˜ í™•ë¥  ë²¡í„°ì˜ ë™ì‘ì„ ì„¤ëª…
    - ì „ìëŠ” ì•Œê³ ë¦¬ì¦˜ ì…ë ¥ê³¼ ì¶œë ¥ì„ êµ¬ì„±í•˜ë©°, ìˆ¨ê²¨ì§„ ë‹¨ìœ„ëŠ” ìš°ë¦¬ê°€ ë°°ìš°ê³  ì‹¶ì€ ì ì¬ì ì¸ ìš”ì†Œ    
    
![rbm1](https://recodatasets.blob.core.windows.net/images/RBM1.png)

- moviellens ì˜ ì…ë ¥ì€ 1ì—ì„œ 5ê¹Œì§€ì˜ ë“±ê¸‰ìœ¼ë¡œ êµ¬ì„±ë¨. ë”°ë¼ì„œ ì§‘í•© = 1,2,3,4,5ì—ì„œ ê°’ì„ ì·¨í•˜ëŠ” m visible ë³€ìˆ˜ì˜ ì´ì‚° êµ¬ì„± ê³µê°„ì„ ê³ ë ¤í•´ì•¼ í•œë‹¤. 
- ì‹œìŠ¤í…œì˜ ì „ì—­ êµ¬ì„±ì€ v = (v1,v2, ..., vm) mvì— ì˜í•´ ê²°ì •ë˜ë©° ë“±ê¸‰ì´ ë§¤ê²¨ì§€ì§€ ì•Šì€ ì˜í™”ì— ëŒ€í•´ 0ì„ ì·¨í•¨. ë˜í•œ hidden Unitë¥¼ ì§€ì •í•´ì•¼ í•¨
    - ëª¨ë“  ì˜í™”ì— ëŒ€í•œ í‰ì ì´ visible ë…¸ë“œ (v1, v2, ..., vm)
    - íŠ¹ì • ë‹¨ìœ„ê°€ í™œì„±ì¸ì§€ ì•„ë‹Œì§€, hidden ë…¸ë“œ, h = (h1,h2, ..., hn) hë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì„ì˜ì˜ ì´ì§„ ë³€ìˆ˜ h = 0,1ë¡œ ì·¨í•¨ (ê°ê°ì˜ ì›ì†Œë“¤ì´ 0 ë˜ëŠ” 1ì„ í™•ë¥ ì ìœ¼ë¡œ ê°€ì§€ê³  ìˆë‹¤ê³  ê°€ì •)
    - ìˆ¨ê²¨ì§„ ë‹¨ìœ„ëŠ” ì˜í™” ì¥ë¥´ì™€ ê°™ì€ ì†ì„±ì„ ì„¤ëª…í•  ìˆ˜ ìˆìŒ. ì˜ˆë¥¼ ë“¤ì–´, ê³µìƒ ê³¼í•™ / ê³µí¬ ì˜í™”ê°€ ì£¼ì–´ì§€ë©´ í•´ë‹¹ ì†ì„±ì„ ì„¤ëª…í•˜ëŠ” ìˆ¨ê²¨ì§„ ë‹¨ìœ„ë§Œ í™œì„±í™”ë˜ì–´ì•¼ í•¨. ì´ëŸ¬í•œ ì‹œìŠ¤í…œì— ëŒ€í•œ ìµœì†Œ ëª¨ë¸ì€ ë‹¤ìŒ í•´ë°€í„´ì— ì˜í•´ ì •ì˜ë©ë‹ˆë‹¤.

![](https://cdn-images-1.medium.com/max/1600/1*ZY4c980_7MfEMYTIi6jvTw.png)

$$H = - \sum_{i,j \in G} v_i \, w_{ij} \, h_j - \sum_{i=1}^m v_i \, a_i - \sum_{j=1}^n h_i \, b_i$$

- E(v,h) = H (RBMì˜ ì—ë„ˆì§€ í•¨ìˆ˜)
- ì²« ë²ˆì§¸ ìš©ì–´ëŠ” ê°€ì‹œì ì¸ ë‹¨ìœ„ì™€ ìˆ¨ê²¨ì§„ ë‹¨ìœ„ ì‚¬ì´ì˜ ìƒê´€ ê´€ê³„ë¥¼ í¬ì°©í•˜ëŠ” "interaction term"ì´ë©° ë‹¤ë¥¸ ë‘ ìš©ì–´ëŠ” ë‹¨ìœ„ì˜ í¸í–¥ì„ ê³ ë ¤í•˜ì—¬ "latent term"ì…ë‹ˆë‹¤. 

- ìƒê´€ í–‰ë ¬ $ w_ij $ì™€ ë‘ ê°€ì§€ í¸í–¥ $ a_i $ ë° $ b_i $ëŠ” ì ì ˆí•˜ê²Œ ì •ì˜ëœ ë¹„ìš© í•¨ìˆ˜ì˜ ìµœì†Œí™”ë¡œ ê³ ì •ë  í•™ìŠµ ë§¤ê°œ ë³€ìˆ˜ì…ë‹ˆë‹¤. 
- ë¹„ì§€ë„ í•™ìŠµ ë¬¸ì œ, ì¦‰. ì‹¤ì œ ì¶œë ¥ì´ ì—†ìœ¼ë¯€ë¡œ ì˜ˆì¸¡ê³¼ ë ˆì´ë¸”ì´ ì§€ì •ëœ ë°ì´í„° ì‚¬ì´ì˜ ì—ëŸ¬ í•¨ìˆ˜ë¥¼ ì§ì ‘ ìµœì†Œí™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 
    - ëª¨ë“  SM ë¬¸ì œì—ì„œì™€ ë§ˆì°¬ê°€ì§€ë¡œ ìµœì†Œí™”í•  ìˆ˜ ìˆëŠ” ì ì ˆí•œ quantityì€ ììœ  ì—ë„ˆì§€ì…ë‹ˆë‹¤ 

$$ F =- \log Z =- \log \sum_{ v_i, h_i } P(v, h) $$.

- í™•ë¥  ì´ë¡ ì˜ ì–¸ì–´ì—ì„œ ìœ„ì˜ quantity ì€ cumulant generating function(mgf ë¡œê·¸)ì…ë‹ˆë‹¤. 
- ììœ  ì—ë„ˆì§€ë¥¼ í‰ê°€í•˜ëŠ” í•œ ê°€ì§€ ë°©ë²•ì€ [Markov-chain ëª¬í…Œì¹´ë¥¼ë¡œ ìƒ˜í”Œë§] ì•Œê³ ë¦¬ì¦˜ì„ Metropolis-Hastingê³¼ ê°™ì´ ì‚¬ìš©í•˜ëŠ” ê²ƒ
- ê¹ìŠ¨ ìƒ˜í”Œë§ì€ ëª¬í…Œ ì¹´ë¥¼ë¡œë³´ë‹¤ ë¹ ë¥´ë‹¤ëŠ” ì´ì ì´ ìˆìŠµë‹ˆë‹¤. candidate Fë¥¼ ë°œê²¬í•˜ë©´ Fë¥¼ ìµœì†Œí™”í•˜ì—¬ í•™ìŠµ ë§¤ê°œ ë³€ìˆ˜ë¥¼ ìˆ˜ì •, ë‹¤ìŒ ì„¹ì…˜ì—ì„œ ì´ ë°©ë²•ì´ ì‹¤ì œë¡œ ì–´ë–»ê²Œ ì‘ë™í•˜ëŠ”ì§€ ì‚´í´ë³´ì.

## 1.3 Learning Algorithm 

- Joint í™•ë¥  ë¶„í¬ì—ì„œ ì§ì ‘ ìƒ˜í”Œë§í•˜ëŠ” ëŒ€ì‹ , ì¡°ê±´ë¶€ ë¶„í¬ë¥¼ í‰ê°€í•  ìˆ˜ ìˆìŒ

$$ P(v, h) = P(v|h) P(h) = P(h|v) P(v) $$ 

![](https://cdn-images-1.medium.com/max/1000/1*NxzVmlmv6KDqO2k77WnfnA.png)
![](https://cdn-images-1.medium.com/max/1000/1*yx_C_ItC8aCUYbHhCJQY5g.png)
![](https://cdn-images-1.medium.com/max/1000/1*6BMmNqK8H3a_BFSq5K3j-A.png)

![](https://image.slidesharecdn.com/rbmpresentation-160427115516/95/restricted-boltzman-machine-rbm-presentation-of-fundamental-theory-44-638.jpg?cb=1461758166)

- negative log likelihoodë¥¼ êµ¬í•˜ëŠ” ê³¼ì •ì˜ ë‘ê°€ì§€ í…€ì´ positive ë‹¨ê³„, negative ë‹¨ê³„
- ì—¬ê¸°ì„œ ë‘ ë²ˆì§¸ equalityì€ ëª¨ë¸ì´ ë°©í–¥ì´ ì—†ê±°ë‚˜, ë¬¼ë¦¬ì ìœ¼ë¡œ í‰í˜•ì„ ì´ë£¨ê³  ìˆë‹¤ëŠ” ì‚¬ì‹¤ì—ì„œ ë”°ë¦…ë‹ˆë‹¤. ê¹ìŠ¤ ìƒ˜í”Œë§ì€ ê¸°ë³¸ì ìœ¼ë¡œ positive ë‹¨ê³„ ë°  negative ë‹¨ê³„ë¡œ ë¶ˆë¦¬ëŠ” ë‘ ë‹¨ê³„ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.
- Positive ë‹¨ê³„? logë¥¼ ì·¨í•˜ë©´ì„œ ë¶„ìì— í•´ë‹¹í•˜ëŠ” ê²ƒì˜ gradient (input nodeì˜ ê°’ë“¤ê³¼ ê·¸ë¡œ ì¸í•´ ì—°ê²°ëœ hidden nodeì˜ ê°’ì´ 1ì´ ë  í™•ë¥ )
- Neagtive ë‹¨ê³„? ë¶„ëª¨ì¸ Zì˜ gradient (ìƒ˜í”Œë§ì„ í†µí•´ ê°’ ì¶”ì •, ëª¨ë¸ì˜ í‰ê· ê°’ê³¼ ê°™ì€ input ê°’ê³¼ ê·¸ë¡œ ì¸í•´ ì—°ê²°ëœ hidden nodeì˜ ê°’ì´ 1ì´ ë  í™•ë¥ )
- ìµœì¢…ì ìœ¼ë¡œ êµ¬í•´ì§€ëŠ” gradient ê°’ì€ positive term - negative termì´ ë¨ (ë‘˜ ì°¨ì´ë§Œí¼ ë³´ì •í•´ì„œ weightì™€ ë°”ì´ì–´ìŠ¤ë¥¼ ì—…ë°ì´íŠ¸)


![](https://cdn-images-1.medium.com/max/1000/1*ZY4c980_7MfEMYTIi6jvTw.png)
![](https://cdn-images-1.medium.com/max/1000/1*De0RDPU_XRqT0BMAVE4vqA.png)
![](https://cdn-images-1.medium.com/max/1000/1*UMbNSJVSmAgqkVnQKA62yg.png)
![](http://deeplearning.net/tutorial/_images/math/71c8949ae03ee393109b8e5adc37c3c4a9aa1e35.png)


[ì°¸ê³  ìë£Œ](https://www.slideshare.net/SeongwonHwang/restricted-boltzman-machine-rbm-presentation-of-fundamental-theory)

### Positive 

- ë°ì´í„°ì— Visible ë‹¨ìœ„ë¥¼ ìˆ˜ì •í•˜ê³  ì¦‰ ì…ë ¥ ë²¡í„° ì „ì²´ì—ì„œ j ë²ˆì§¸ ìˆ¨ê²¨ì§„ ë‹¨ìœ„ê°€ í™œì„±í™” ë  í™•ë¥ ì„ ê³„ì‚°í•˜ì‹­ì‹œì˜¤. ì‹¤ì œë¡œëŠ” ìƒì„± í•¨ìˆ˜ë¥¼ í‰ê°€í•˜ëŠ” ê²ƒì´ í¸ë¦¬í•©ë‹ˆë‹¤.

$$ Z[v,b] = \prod_j \sum_{h_j = 0,1}  e^{(\sum_i w_{ij} v_i + b_j) h_j} = \prod_j \left( 1+  e^{\sum_i w_{ij} v_i + b_j} \right).$$

- ìš°ë¦¬ê°€ ì–»ì„ ìˆ˜ ìˆëŠ” ë°”ì´ì–´ìŠ¤ì™€ ê´€ë ¨í•˜ì—¬ ê¸°ìš¸ê¸°ë¥¼ ì·¨í•¨

$$\frac{\partial}{\partial b_j}\log Z[v,b] =  \frac{1}{1+ e^{-(\sum_i w_{ij} v_i + b_j)}} = \sigma( \phi_j(v, b) ),$$

where $\phi_j(v,b) = \sum_i w_{ij} v_i + b_j $ and we have identified the logistic function $\sigma(.) \equiv P(h_j=1|v,b)$. 


### Negative 

- ìˆ¨ê²¨ì§„ ë‹¨ìœ„ì˜ í‘œë³¸ ê°’ì„ ì‚¬ìš©í•˜ì—¬ $ P (v_i = q | h) $ **, $ q = 1, ..., 5 $ ë¥¼ í‰ê°€í•˜ì‹­ì‹œì˜¤. ë‹¤í•­ì‹ì— ì˜í•´ ì£¼ì–´ì§

$$ P(v_i = q |h,a) =  \prod_{v_i=1}^q e^{v_i (\sum_j w_{ij} \, h_j + a_i ) }/Z_q $$,

- ì—¬ê¸°ì„œ $ Z_q $ëŠ” $ q $ ê²°ê³¼ì— ëŒ€í•´ ê³„ì‚°ëœ íŒŒí‹°ì…˜ í•¨ìˆ˜ì…ë‹ˆë‹¤.
- ë§ˆì§€ë§‰ìœ¼ë¡œ ìœ„ì˜ ë¶„í¬ì—ì„œ $ v_i $ì˜ ê°’ì„ ìƒ˜í”Œë§í•©ë‹ˆë‹¤. ë¶„ëª…íˆ ìƒˆë¡œìš´ $ v_i $ëŠ” ì ì–´ë„ í›ˆë ¨ ì‹œì‘ ë‹¨ê³„ê°€ ì•„ë‹Œ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•œ í‚¤ì›Œë“œ ì¼ í•„ìš”ëŠ” ì—†ìŠµë‹ˆë‹¤. 
- ìœ„ì˜ ë‹¨ê³„ëŠ” $ k $ ë²ˆ ë°˜ë³µë˜ë©°, ì—¬ê¸°ì„œ $ k $ëŠ” ì¼ë°˜ì ìœ¼ë¡œ ì£¼ì–´ì§„ í”„ë¡œí† ì½œì— ë”°ë¼ í•™ìŠµ ì¤‘ì— ì¦ê°€í•©ë‹ˆë‹¤.
- ê°ê°ì˜ k-step ê¹ìŠ¤ ìƒ˜í”Œë§ì˜ ëì—ì„œ $ k = 0 $ (ì£¼ì–´ì§„ v)ì™€ k-steps ì´í›„ì˜ ììœ  ì—ë„ˆì§€ ê°„ì˜ ì°¨ì´ë¥¼ í‰ê°€í•©ë‹ˆë‹¤

$$ \Delta F = F_0 - F_k, $$

and update the learning parameters $w_{ij}$, $b_i$ and $a_i$: 

$$ \frac{\partial}{\partial b_j} \Delta F = \frac{\partial}{\partial b_j} (\log Z_0[v,b] - \log Z_k[v,b]) = P_0(h_j=1|v,b) - P_k(h_j=1|v,b) $$

$$ \frac{\partial}{\partial w_{ij} } \Delta F = v_i \, P_0(v_i = q|h, a) - v_i P_k(v_i| h,a) \equiv \langle v_i\rangle_0 - \langle v_i \rangle_k. $$

- ê³¼ì •ì€ ê° í›ˆë ¨ì‹œê¸°ë§ˆë‹¤, ê²°êµ­ $ \ Delta F = 0 $ê¹Œì§€ ë°˜ë³µëœë‹¤. ì¦‰, í•™ìŠµëœ ë¶„í¬ëŠ” ê²½í—˜ì ìœ¼ë¡œ ì •í™•í•˜ê²Œ ì¬í˜„ëœë‹¤. 
- ì´ ì˜ë¯¸ì—ì„œ $ v_i $ëŠ” ëª¨ë¸ì˜ ì…ë ¥ê³¼ ì¶œë ¥ì„ ëª¨ë‘ ì œê³µí•©ë‹ˆë‹¤. $ w_ {ij} $ì—ëŠ” ì‚¬ìš©ì íˆ¬í‘œì˜ ìƒê´€ ê´€ê³„ì— ëŒ€í•œ ì •ë³´ê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ì´ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµëœ marginal distributionì—ì„œ ìƒ˜í”Œë§í•˜ì—¬ ë³´ì´ì§€ ì•ŠëŠ” ì˜í™”ì— ëŒ€í•œ ë“±ê¸‰ì„ ìƒì„± í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

$$ \langle v_i \rangle = \sum_{v_i} v_i \, P(v) $$ 


![](http://deeplearning.net/tutorial/_images/math/aaf04e6e2c43def4c009e913bff8a44a6baffa65.png)

- ì „ì²´ ì›Œí¬ í”Œë¡œê°€ ì•„ë˜ì— ìš”ì•½ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

![gibbs](https://recodatasets.blob.core.windows.net/images/Gsampling.png)


## 2. TensorFlow implemetation and model parameters 

- í•´ë‹¹ ì„¹ì…˜ì—ì„œëŠ” ì•Œê³ ë¦¬ì¦˜ì´ Tensorflowì—ì„œ êµ¬í˜„ë˜ëŠ” ë°©ë²•ê³¼ í›ˆë ¨ ì¤‘ì— ì‚¬ìš©ìê°€ ì‚¬ìš©ì ì •ì˜ í•  ìˆ˜ìˆëŠ” ë§¤ê°œ ë³€ìˆ˜ë¥¼ ê°„ëµí•˜ê²Œ ì„¤ëª…í•©ë‹ˆë‹¤. 
- ë˜í•œ ì¶”ì²œì‹œìŠ¤í…œ ì‘ì—…ì—ì„œ RBM ëª¨ë¸ì„ êµìœ¡ í•  ë•Œ ì‚¬ìš©ë˜ëŠ” ëª‡ ê°€ì§€ ëª¨ë²” ì‚¬ë¡€ì— ëŒ€í•´ ì„¤ëª…í•©ë‹ˆë‹¤. ì¶”ê°€ ê¸°ìˆ  ì •ë³´ëŠ” ì½”ë“œì—ì„œ ì§ì ‘ ì„¤ëª…í•©ë‹ˆë‹¤.

- Tensorflow (TF)ëŠ” ë¹ ë¥´ê³  íš¨ìœ¨ì ì¸ ë°©ë²•ìœ¼ë¡œ ë”¥ëŸ¬ë‹(DL) ëª¨ë¸ì„ ê°œë°œí•˜ëŠ” ì˜¤í”ˆì†ŒìŠ¤ í”„ë ˆì„ ì›Œí¬ì…ë‹ˆë‹¤. 
- DL í”„ë ˆì„ ì›Œí¬ì˜ ê³µí†µëœ íŠ¹ì„± ì¤‘ í•˜ë‚˜ëŠ” autodifferentiation, ì¦‰ ì—¬ê¸°ì—ì„œ íŠ¹íˆ ìœ ìš©í•  ê·¸ë¼ë””ì–¸íŠ¸ì˜ symbolic í‰ê°€ì…ë‹ˆë‹¤. 
- TFì˜ ë˜ ë‹¤ë¥¸ ì´ì ì€ ê³„ì‚° ê·¸ë˜í”„ì— ì •ì˜ ëœ ê¸°í˜¸ ì—°ì‚°ì˜ ìƒì„± ë° ìµœì í™”ë¡œ CPUì™€ GPU ëª¨ë‘ì—ì„œ ë¹ ë¥´ê³  í™•ì¥ ê°€ëŠ¥í•œ ë°°ì¹˜ì…ë‹ˆë‹¤. 
- ë¶ˆí–‰íˆë„ TFëŠ” ì§€ë„ í•™ìŠµ ê³¼ì œì— ë§ì¶° ë§Œë“¤ì–´ ì¡Œìœ¼ë¯€ë¡œ ë¹„ì§€ë„ í•™ìŠµ ëª¨ë¸ì— ì ìš©í•˜ë ¤ë©´ ë” ë§ì€ ì‘ì—…ì´ í•„ìš”í•©ë‹ˆë‹¤. 

- RBM ëª¨ë¸ì€ ê·¸ë˜í”„ë¥¼ ì‘ì„±í•˜ê³  ìƒ˜í”Œë§, í•™ìŠµ ë° ì¶”ë¡ ì„ ìˆ˜í–‰í•˜ëŠ” ì—¬ëŸ¬ ê°€ì§€ ë°©ë²•ìœ¼ë¡œ í´ë˜ìŠ¤ë¡œ ì¸ìŠ¤í„´ìŠ¤í™”ë©ë‹ˆë‹¤. ê·¸ë˜í”„ì˜ ê³¨ê²©ì€ í´ë˜ìŠ¤ê°€ ì¸ìŠ¤í„´ìŠ¤í™”ë˜ëŠ” ìˆœê°„ì— ì‘ì„±ë©ë‹ˆë‹¤. í•„ìˆ˜ ì…ë ¥ë€ :

- `hidden_units` integer (Default =500) : number of hidden units
- `training_epoch`integer (Default = 20): number of training epochs 
- `minibatch_size`integer (Default = 100): size of the batch to be chosen at random at each training epoch 

The optional parameters are: 

- `keep_prob` : float (Default = 0.7) we use dropout regularization on the hidden units, so this parameter specifies the probability of keeping the connection to a hidden unit active. Dropout will affect specific matrix elements of $w_{ij}$, decreasing in this way the model's complexity and improving generalization. 

- `sampling_protocol` : Array (Default = $[50, 70, 80,90,100]$) percentage of the entire training epochs when the the k-sampling step is increased in an annealing fashion. In the default case, the first 50% of the training epochs are sampled with a single k-step. As training converges, the number of k-steps is increased by $1$ at each percentage.

- `debug`: Boolean (Default = False) if True, prints the output of some of the intermediate steps for inspection. 

- `with_metrics`: Boolean (Default= False) if True it evaluates, print and finally plot the mean squared root error per training epoch on the training set. At the end, it also evaluates and print the total model accuracy both on the training and test set. We suggest to switch it off only for benchmarking execution time.  

- `init_stdv`: float (Default = 0.1) standard deviation used to inititialize the correlation matrix. 

- `learning_rate`: float (Default = 0.004) init learning rate used in the optimization algorithm. Note that the optimizer uses a different, effective learning rate scaled to the batch size $\alpha$ = `learning_rate/minibatch_size`. 

- `display_epoch `: integer (Default = 10) the number of epochs after which the rmse error is printed out during the learning phase. 


- ì„ íƒ ì‚¬í•­ì´ì§€ë§Œ ë‹¤ë¥¸ ì¶”ì²œ ì‹œìŠ¤í…œì„ ìœ„í•´ ìƒ˜í”Œë§ _protocol ì„ ìˆ˜ì •í•´ì•¼í•  ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ ë°ì´í„° ì„¸íŠ¸ë¥¼ í›ˆë ¨í•  ë•Œ ì´ë¥¼ ì—¼ë‘ì— ë‘ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.

# 3 Data preparation and inspection 

- Movielens ë°ì´í„° ì„¸íŠ¸ëŠ” ì‚¬ìš© ê°€ëŠ¥í•œ ë“±ê¸‰ì˜ ìˆ˜ë¥¼ ë‚˜íƒ€ë‚´ëŠ” í¬ê¸°ê°€ ë‹¤ë¦…ë‹ˆë‹¤. ì‚¬ìš©ì ë° ë“±ê¸‰ ì˜í™” ìˆ˜ëŠ” ë‹¤ë¥¸ ë°ì´í„° ì„¸íŠ¸ì—ì„œ ë³€ê²½ë©ë‹ˆë‹¤. 
- ì´ ë°ì´í„°ëŠ” íŠ¹ì • ì‚¬ìš©ìê°€ íŠ¹ì • í•­ëª©ì„ í‰ê°€í•œ ì‹œì ì„ ë‚˜íƒ€ë‚´ëŠ” ì‚¬ìš©ì ID, item ID, ratings ë° timestampë¥¼ í¬í•¨í•˜ì—¬ pandas ë°ì´í„° í”„ë ˆì„ì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤. 
- ë§ˆì§€ë§‰ ê¸°ëŠ¥ì€ ëª…ì‹œì ìœ¼ë¡œ í¬í•¨ë  ìˆ˜ ìˆì§€ë§Œ ì—¬ê¸°ì—ì„œëŠ” ê³ ë ¤ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì„ íƒì˜ ê¸°ë³¸ ê°€ì •ì€ ì‚¬ìš©ìì˜ ì·¨í–¥ì´ ì•½í•œ ì‹œê°„ì— ì˜ì¡´í•œë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤. 

- ì‚¬ìš©ìì˜ ì·¨í–¥ì€ ì¼ë°˜ì ìœ¼ë¡œ ì¼ë°˜ì ì¸ ê¶Œì¥ ì‹œê°„ ì²™ë„ (ì˜ˆ :. ì‹œê°„/ì¼). ê²°ê³¼ì ìœ¼ë¡œ ìš°ë¦¬ê°€ ë°°ìš°ê³  ì‹¶ì€ joint í™•ë¥  ë¶„í¬ëŠ” ì‹œê°„ì— ë”°ë¼ dependentí•˜ê²Œ ê³ ë ¤ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 
- ê·¸ëŸ¼ì—ë„ ë¶ˆêµ¬í•˜ê³  íƒ€ì„ ìŠ¤íƒ¬í”„ëŠ” ì»¨í…ìŠ¤íŠ¸ ë³€ìˆ˜ë¡œ ì‚¬ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì£¼ë§ì—ëŠ” íŠ¹ì • ì˜í™”ë¥¼ ì¶”ì²œí•˜ê³  í‰ì¼ì—ëŠ” ë‹¤ë¥¸ ì˜í™”ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.


- ì•„ë˜ëŠ” ë¨¼ì € pandas ë°ì´í„° í”„ë ˆì„ì— ë‹¤ë¥¸ movielens ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ì‚¬ìš©ì / affinity ë§¤íŠ¸ë¦­ìŠ¤ê°€ ì–´ë–»ê²Œ êµ¬ì¶•ë˜ê³  train / test ì„¸íŠ¸ê°€ ì–´ë–»ê²Œ ìƒì„±ë˜ëŠ”ì§€ ì„¤ëª…í•©ë‹ˆë‹¤. 
- ì´ ì ˆì°¨ëŠ” ì—¬ê¸°ì—ì„œ ê³ ë ¤ëœ ëª¨ë“  ë°ì´í„° ì„¸íŠ¸ì— ê³µí†µì ì´ë¯€ë¡œ 1m ë°ì´í„° ì„¸íŠ¸ì— ëŒ€í•´ì„œë§Œ ìì„¸íˆ ì„¤ëª…í•©ë‹ˆë‹¤.

- ìš°ë¦¬ëŠ” ë‹¤ì–‘í•œ ë°ì´í„° ì„¸íŠ¸ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ëŠ” ê²ƒìœ¼ë¡œ ì‹œì‘í•©ë‹ˆë‹¤.


```python
MOVIELENS_DATA_SIZE = '100k'

mldf_100k = movielens.load_pandas_df(
    size=MOVIELENS_DATA_SIZE,
    header=['userID','movieID','rating','timestamp']
)

# Convert the float precision to 32-bit in order to reduce memory consumption 
mldf_100k.loc[:, 'rating'] = mldf_100k['rating'].astype(np.int32) 

mldf_100k.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>userID</th>
      <th>movieID</th>
      <th>rating</th>
      <th>timestamp</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>196</td>
      <td>242</td>
      <td>3</td>
      <td>881250949</td>
    </tr>
    <tr>
      <th>1</th>
      <td>186</td>
      <td>302</td>
      <td>3</td>
      <td>891717742</td>
    </tr>
    <tr>
      <th>2</th>
      <td>22</td>
      <td>377</td>
      <td>1</td>
      <td>878887116</td>
    </tr>
    <tr>
      <th>3</th>
      <td>244</td>
      <td>51</td>
      <td>2</td>
      <td>880606923</td>
    </tr>
    <tr>
      <th>4</th>
      <td>166</td>
      <td>346</td>
      <td>1</td>
      <td>886397596</td>
    </tr>
  </tbody>
</table>
</div>




```python
MOVIELENS_DATA_SIZE = '1m'

mldf_1m = movielens.load_pandas_df(
    size=MOVIELENS_DATA_SIZE,
    header=['userID','movieID','rating','timestamp']
)

# Convert the float precision to 32-bit in order to reduce memory consumption 
mldf_1m.loc[:, 'rating'] = mldf_1m['rating'].astype(np.int32) 

mldf_1m.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>userID</th>
      <th>movieID</th>
      <th>rating</th>
      <th>timestamp</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>1193</td>
      <td>5</td>
      <td>978300760</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>661</td>
      <td>3</td>
      <td>978302109</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>914</td>
      <td>3</td>
      <td>978301968</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>3408</td>
      <td>4</td>
      <td>978300275</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>2355</td>
      <td>5</td>
      <td>978824291</td>
    </tr>
  </tbody>
</table>
</div>



### 3.1 Split the data using the stratified splitter  

- ë‘ ë²ˆì§¸ ë‹¨ê³„ë¡œ, ìš°ë¦¬ëŠ” ë™ì¼í•œ í–‰ë ¬ í¬ê¸°ë¥¼ ìœ ì§€í•¨ìœ¼ë¡œì¨ ë°ì´í„°ë¥¼ í›ˆë ¨ ë° í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ë¶„í• í•©ë‹ˆë‹¤. ë¶„ëª…íˆ ë‘ í–‰ë ¬ì€ ì„œë¡œ ë‹¤ë¥¸ ë¹„ìœ¨ë¡œ ë‹¤ë¥¸ ë“±ê¸‰ì„ í¬í•¨í•©ë‹ˆë‹¤.

- ì²«ì§¸, AffinityMatrix í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ì„¹ì…˜ 1.1ì— ì •ì˜ëœ $ (m, n) $ ì‚¬ìš©ì / affinity ë§¤íŠ¸ë¦­ìŠ¤ $ X $ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. 
- í¬ì†Œì„± ë¹„ìœ¨ì„ ë°˜í™˜. ì˜ˆë¥¼ ë“¤ì–´, 1m ë°ì´í„° ì„¸íŠ¸ì˜ ê²½ìš° í–‰ë ¬ í•­ëª©ì˜ 95%ëŠ” 0ì…ë‹ˆë‹¤. í•™ìŠµ ê³¼ì œì— ëŒ€í•œ ë„ì „ ê³¼ì œë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ë°ì´í„° í¬ì¸íŠ¸ì˜ 5%ë§Œìœ¼ë¡œ í•­ëª©ì˜ 95%ë¥¼ ìˆ˜ì •í•©ë‹ˆë‹¤.


- ë‘˜ì§¸, numpy_stratified_split()ì„ ì´ìš©í•´ X ë°ì´í„°ë¥¼ í›ˆë ¨ ì„¸íŠ¸ì™€ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ë‚˜ëˆ ë¼. ê¸°ë³¸ì ìœ¼ë¡œ ìš°ë¦¬ëŠ” 75%ì—ì„œ 25%ì˜ ë¹„ìœ¨ì„ ì„ íƒí•©ë‹ˆë‹¤. - ë¶„í•  í•¨ìˆ˜ëŠ” ëª¨ë“  ì‚¬ìš©ìì— ëŒ€í•´ ë“±ê¸‰ ì˜í™”ì˜ 25%ë¥¼ ì„ íƒí•˜ê³  ìƒˆë¡œìš´ í…ŒìŠ¤íŠ¸ ë§¤íŠ¸ë¦­ìŠ¤ë¡œ ì´ë™í•©ë‹ˆë‹¤. ë°ì´í„°ë¥¼ ë¶„í• í•˜ëŠ” ì´ëŸ¬í•œ ë°©ë²•ì€ ë¡œì»¬ (ì‚¬ìš©ì ë³„)ê³¼ ì „ ì„¸ê³„ì ìœ¼ë¡œ í›ˆë ¨ / í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œ ë“±ê¸‰ ë¶„í¬ê°€ ë™ì¼í•˜ê²Œ ìœ ì§€ë˜ë„ë¡ í•©ë‹ˆë‹¤. 


### Train

|  $X_{tr}$   |$i_1$  |$i_2$  |$i_3$  |  $...$ |$i_n$  |    
|-----|-------|-------|-------|--------|-------|
|$u_1$|$0$    |$0$    |$2$    |$0...$  |$0$    |
|$u_2$|$0$    |$0$    |$3$    |$0...$  |$0$    |
|$...$|$...$  |$...$  |$...$  |$...$   |$...$  |
|$u_m$|$3$    |$0$    |$0$    |$0...$  |$2$    |


### Test 

| $X_{tst}$    |$i_1$  |$i_2$  |$i_3$  |  ... |$i_n$  | 
|-----|-------|-------|-------|------|-------|
|$u_1$|5      |0      |0      |0 ... |1      |
|$u_2$|0      |0      |0      |4 ... |0      |
|...  |...    |...    |...    |...   |...    |
|$u_m$|0      |3      |0      |5...  |0      |

- í›ˆë ¨ ë° í…ŒìŠ¤íŠ¸ í–‰ë ¬ì€ ì •í™•íˆ ë™ì¼í•œ dimensionsë¥¼ ê°–ëŠ”ë‹¤ (ì¦‰, ë™ì¼í•œ ìˆ˜ì˜ ì‚¬ìš©ìì™€ ì˜í™”)ì´ì§€ë§Œ ë‹¤ë¥¸ ë“±ê¸‰ì„ í¬í•¨í•©ë‹ˆë‹¤. ëª¨ë¸ì„ í›ˆë ¨í•˜ë©´ ì¶”ë¡  ì‹œê°„ì— í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ì‚¬ìš©ì ë²¡í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë“±ê¸‰ì— ëŒ€í•œ ìœ ì¶” ê°’ì„ ì–»ìŠµë‹ˆë‹¤.


```python
#to use standard names across the analysis 
header = {
        "col_user": "userID",
        "col_item": "movieID",
        "col_rating": "rating",
    }
```


```python
#instantiate the splitter 
am1m = AffinityMatrix(DF = mldf_1m, **header)

#obtain the sparse matrix 
X1m = am1m.gen_affinity_matrix()
```


```python
print(am1m.Nitems)
```

    3706



```python
print(am1m.Nusers)
```

    6040



```python
X1m.shape
```




    (6040, 3706)




```python
np.random.seed(42)  # set the random seed
test_cut = int((1 - 0.75) * 100)  # percentage of ratings to go in the test set
print(test_cut)

# initialize train and test set matrices
Xtr = X1m.copy()
Xtst = X1m.copy()

# find the number of rated movies per user
rated = np.sum(Xtr != 0, axis=1)

# for each user, cut down a test_size% for the test set
tst = np.around((rated * test_cut) / 100).astype(int)
```

    25



```python
(rated * test_cut) / 100
```




    array([13.25, 32.25, 12.75, ...,  5.  , 30.75, 85.25])




```python
np.sum(Xtr != 0, axis=1)
```




    array([ 53, 129,  51, ...,  20, 123, 341])




```python
tst
```




    array([13, 32, 13, ...,  5, 31, 85])




```python
idx = np.asarray(np.where(Xtr[1] != 0))[0].tolist()
```


```python
idx_tst = np.random.choice(idx, tst[1], replace=False)
```


```python
idx_tst
```




    array([101,  86,  65,  77, 160, 102, 115, 151, 127,  72, 141,  73, 110,
            23, 143, 146,  82, 126, 139, 130,  64,  56, 165,  57, 170,  91,
           116, 124,  93,   0,  58,  88])




```python
for u in range(6040):
        # For each user obtain the index of rated movies
        idx = np.asarray(np.where(Xtr[u] != 0))[0].tolist()

        # extract a random subset of size n from the set of rated movies without repetition
        idx_tst = np.random.choice(idx, tst[u], replace=False)
        idx_train = list(set(idx).difference(set(idx_tst)))

        # change the selected rated movies to unrated in the train set
        Xtr[u, idx_tst] = 0
        # set the movies that appear already in the train set as 0
        Xtst[u, idx_train] = 0
```

- ë‹¤ìŒìœ¼ë¡œ, ìœ„ì˜ í–‰ë ¬ì„ í›ˆë ¨ ë°ì´í„°ë¡œ ë¶„í• í•˜ê³  í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ í¬ì†Œ í–‰ë ¬ì„ ì„¤ì •í•©ë‹ˆë‹¤


```python
Xtr_1m, Xtst_1m = numpy_stratified_split(X1m)
```


```python
Xtr_1m.shape
```




    (6040, 3706)




```python
Xtst_1m.shape
```




    (6040, 3706)




```python
Xtr_1m
```




    array([[5, 3, 4, ..., 0, 0, 0],
           [5, 0, 0, ..., 0, 0, 0],
           [0, 0, 0, ..., 0, 0, 0],
           ...,
           [0, 0, 0, ..., 0, 0, 0],
           [0, 0, 0, ..., 0, 0, 0],
           [4, 0, 0, ..., 0, 0, 0]], dtype=int32)




```python
Xtst_1m
```




    array([[0, 0, 0, ..., 0, 0, 0],
           [0, 0, 0, ..., 0, 0, 0],
           [0, 0, 0, ..., 0, 0, 0],
           ...,
           [0, 0, 0, ..., 0, 0, 0],
           [0, 0, 0, ..., 0, 0, 0],
           [0, 0, 0, ..., 0, 0, 0]], dtype=int32)



- ìŠ¤í”Œë¦¬í„° í•¨ìˆ˜ê°€ ì¼ì •í•˜ê²Œ ìœ ì§€ë˜ë„ë¡ í…ŒìŠ¤íŠ¸ / í›ˆë ¨ ë§¤íŠ¸ë¦­ìŠ¤ì˜ ë“±ê¸‰ ë¶„í¬ë¥¼ ê²€ì‚¬í•˜ëŠ” ê²ƒì´ ìœ ìš©í•©ë‹ˆë‹¤. ì •ê·œí™”ëœ íˆìŠ¤í† ê·¸ë¨ì„ í‘œì‹œí•˜ì—¬ ì´ ì ì„ ê²€ì‚¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤


```python
_, (ax1m, ax2m) = plt.subplots(1, 2, sharey=True, figsize=(10,5))
ax1m.hist(Xtr_1m[Xtr_1m !=0], 5, density= True)
ax1m.set_title('Train')
ax1m.set(xlabel="ratings", ylabel="density")
ax2m.hist(Xtst_1m[Xtst_1m !=0], 5, density= True)
ax2m.set_title('Test')
ax2m.set(xlabel="ratings", ylabel="density")
```




    [Text(0, 0.5, 'density'), Text(0.5, 0, 'ratings')]




![png](images/syleeie/2019-05-05/output_32_1.png)


We now repeat the same operations for the other datasets


```python
#100k
am100k = AffinityMatrix(DF = mldf_100k, **header)
X100k= am100k.gen_affinity_matrix()
Xtr_100k, Xtst_100k = numpy_stratified_split(X100k)
```


```python
_, (ax1k, ax2k) = plt.subplots(1, 2, sharey=True, figsize=(10,5))
ax1k.hist(Xtr_100k[Xtr_100k !=0], 5, density= True)
ax1k.set_title('Train')
ax1k.set(xlabel="ratings", ylabel="density")
ax2k.hist(Xtst_100k[Xtst_100k !=0], 5, density= True)
ax2k.set_title('Test')
ax2k.set(xlabel="ratings", ylabel="density")
```




    [Text(0, 0.5, 'density'), Text(0.5, 0, 'ratings')]




![png](images/syleeie/2019-05-05/output_35_1.png)


- ìœ„ì˜ ê·¸ë¦¼ì—ì„œ ë‘ ë°ì´í„° ì„¸íŠ¸ê°€ ë§¤ìš° ìœ ì‚¬í•œ ë“±ê¸‰ ë¶„í¬ë¥¼ ê°–ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê°€ì¥ í° ì°¨ì´ì ì€ ì‚¬ìš©ì / í•­ëª© ìœ ì‚¬ë„ í–‰ë ¬ì˜ í¬ì†Œì„± ì •ë„ì…ë‹ˆë‹¤. 
- ì´ê²ƒì€ ìœ ì¶”í•  ë°ì´í„° í¬ì¸íŠ¸ì™€ ë“±ê¸‰ì´ ë§¤ê²¨ì§€ì§€ ì•Šì€ ì˜í™”ì˜ ë¹„ìœ¨ì„ ë‚˜íƒ€ë‚´ëŠ” ì¤‘ìš”í•œ ìš”ì†Œì…ë‹ˆë‹¤. ë¶„í•  í•¨ìˆ˜ëŠ” ì‚¬ìš©ì ë³„ì´ ì•„ë‹Œ ì´ (ë˜ëŠ” ë°ì´í„° ì„¸íŠ¸ ë‹¹) sparsnessë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.


```python
#collection of evaluation metrics for later use
def ranking_metrics(
    data_size,
    data_true,
    data_pred,
    time_train,
    time_test,
    K
):

    eval_map = map_at_k(data_true, data_pred, col_user="userID", col_item="movieID", 
                    col_rating="rating", col_prediction="prediction", 
                    relevancy_method="top_k", k= K)

    eval_ndcg = ndcg_at_k(data_true, data_pred, col_user="userID", col_item="movieID", 
                      col_rating="rating", col_prediction="prediction", 
                      relevancy_method="top_k", k= K)

    eval_precision = precision_at_k(data_true, data_pred, col_user="userID", col_item="movieID", 
                               col_rating="rating", col_prediction="prediction", 
                               relevancy_method="top_k", k= K)

    eval_recall = recall_at_k(data_true, data_pred, col_user="userID", col_item="movieID", 
                          col_rating="rating", col_prediction="prediction", 
                          relevancy_method="top_k", k= K)

    
    df_result = pd.DataFrame(
        {   "Dataset": data_size,
            "K": K,
            "MAP": eval_map,
            "nDCG@k": eval_ndcg,
            "Precision@k": eval_precision,
            "Recall@k": eval_recall,
            "Train time (s)": time_train,
            "Test time (s)": time_test
        }, 
        index=[0]
    )
    
    return df_result
```

# 4. Model application, performance and analysis of the results  

- í•´ë‹¹ ëª¨ë¸ì€ TF ì„¸ì…˜ì´ fit() ë°©ë²• ì•ˆì— ìˆ¨ê²¨ì ¸ ìˆì–´ ëª…ì‹œì ì¸ í˜¸ì¶œì´ í•„ìš”í•˜ì§€ ì•Šë„ë¡ Tensorflow (TF) í´ë˜ìŠ¤ë¡œ êµ¬í˜„ë˜ì—ˆìŠµë‹ˆë‹¤. ì•Œê³ ë¦¬ì¦˜ì€ ì„¸ ê°€ì§€ ë‹¨ê³„ë¡œ ì‘ë™í•©ë‹ˆë‹¤.


1) ëª¨ë¸ ì´ˆê¸°í™” : ì—¬ê¸°ì„œ TFì—ê²Œ ê³„ì‚° ê·¸ë˜í”„ë¥¼ ë§Œë“œëŠ” ë°©ë²•ì„ ì•Œë ¤ì¤ë‹ˆë‹¤. ì§€ì •í•  ì£¼ìš” ë§¤ê°œ ë³€ìˆ˜ëŠ” ìˆ¨ê²¨ì§„ ë‹¨ìœ„ì˜ ìˆ˜, í›ˆë ¨ epochs ìˆ˜ ë° ë¯¸ë‹ˆ ë°°ì¹˜ í¬ê¸°ì…ë‹ˆë‹¤.

2) ëª¨ë¸ ì í•©: ë°ì´í„°ì—ì„œ ëª¨í˜•ì„ í›ˆë ¨í•˜ëŠ” ê³³ì…ë‹ˆë‹¤. ì´ ë°©ë²•ì€ ë‘ ê°€ì§€ arguments, ì¦‰ í›ˆë ¨ê³¼ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ í–‰ë ¬ì„ ì·¨í•©ë‹ˆë‹¤. ëª¨ë¸ì€ í›ˆë ¨ ì„¸íŠ¸ì—ì„œë§Œ í›ˆë ¨ë˜ë©°, í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ëŠ” í›ˆë ¨ëœ ëª¨ë¸ì˜ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ì •í™•ë„ë¥¼ í‘œì‹œí•˜ëŠ”ë° ì‚¬ìš©ë˜ë©°, ì°¨ë¡€ë¡œ ì•Œê³ ë¦¬ì¦˜ì˜ ìƒì„± ê¸°ëŠ¥ì„ ì¶”ì •í•©ë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ ìµœì í™” ë™ì‘ì— ëŒ€í•œ ì²« ë²ˆì§¸ ì•„ì´ë””ì–´ë¥¼ ê°–ê¸° ìœ„í•´ ì´ëŸ¬í•œ ì–‘ì„ ë³´ëŠ” ê²ƒì´ ìœ ìš©í•©ë‹ˆë‹¤.

3) ëª¨ë¸ ì˜ˆì¸¡: ì—¬ê¸°ì„œ ë³´ì´ì§€ ì•ŠëŠ” í•­ëª©ì— ëŒ€í•œ ë“±ê¸‰ì„ ìƒì„±í•©ë‹ˆë‹¤. ì¼ë‹¨ ëª¨ë¸ì´ í›ˆë ¨ë˜ê³  ì „ì²´ì ì¸ ì •í™•ì„±ì— ë§Œì¡±í•˜ë©´ í•™ìŠµëœ ë¶„í¬ë¡œë¶€í„° ìƒˆë¡œìš´ ë“±ê¸‰ì„ ìƒ˜í”Œë§í•©ë‹ˆë‹¤. íŠ¹íˆ, ìš°ë¦¬ëŠ” top_k (ì˜ˆ :. 10) ì‚¬ì „ ì •ì˜ ëœ ì ìˆ˜ì— ë”°ë¼ ëŒ€ë¶€ë¶„ì˜ ê´€ë ¨ ì¶”ì²œ ì‚¬í•­. ë‹¤ìŒ ì˜ˆì¸¡ì„ ë¶„ì„í•˜ê³  ë°°í¬í•  ì¤€ë¹„ê°€ ëœ ë°ì´í„° í”„ë ˆì„ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.

## 4.1 1m Dataset


```python
#First we initialize the model class
model_1m = RBM(hidden_units= 1200, training_epoch = 30, minibatch_size= 350, with_metrics=True, debug=True)
```

- fitting ë°©ë²•ì„ ì²˜ìŒ í˜¸ì¶œí•  ë•Œ ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ëŠ” ë° ë” ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ê²ƒì€ TFê°€ GPU ì„¸ì…˜ì„ ì´ˆê¸°í™”í•´ì•¼ í•œë‹¤ëŠ” ì‚¬ì‹¤ ë•Œë¬¸ì…ë‹ˆë‹¤. 
- ì•Œê³ ë¦¬ì¦˜ì„ ë‘ ë²ˆ ì´ìƒ í›ˆë ¨í•  ë•Œì—ëŠ” ê·¸ë ‡ì§€ ì•Šë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë¯¸ë‹ˆë°°ì¹˜ í¬ê¸°ì— ëŒ€í•´ì„œëŠ” í•©ë¦¬ì ì¸ ì‹¤í–‰ ì‹œê°„ì„ ì§€í‚¤ë©´ì„œ ì¼ë°˜í™” ì˜¤ë¥˜ê°€ ì¢‹ì€ ê°’ì„ ì„ íƒí•˜ê³  ì‹¶ë‹¤. 
- í¬ê¸°ê°€ ì‘ì„ìˆ˜ë¡ í™•ë¥ ì  ê¸°ìš¸ê¸° í•˜ê°•ì— ê°€ê¹Œì›Œì§€ì§€ë§Œ í›ˆë ¨ì€ ë” ì˜¤ë˜ ê±¸ë¦½ë‹ˆë‹¤. í° í¬ê¸° ê°’ (ì˜ˆ : ë°°ì¹˜ í¬ê¸°ì˜ 1/2)ì€ í›ˆë ¨ì„ ê°€ì†í™”í•˜ì§€ë§Œ ì¼ë°˜í™” ì˜¤ë¥˜ë¥¼ ì¦ê°€ì‹œí‚µë‹ˆë‹¤.


```python
#Model Fit
train_time = model_1m.fit(Xtr_1m, Xtst_1m)
```

    CD step 1
    CD step 2
    CD step 3
    CD step 4
    CD step 5



![png](images/syleeie/2019-05-05/output_42_1.png)


- í›ˆë ¨í•˜ëŠ” ë™ì•ˆ, í•™ìŠµì´ ì–´ë–»ê²Œ ì§„í–‰ë˜ê³  ìˆëŠ”ì§€ì— ëŒ€í•œ ì•„ì´ë””ì–´ë¥¼ ê°–ê¸° ìœ„í•´ root mean squared error ë¥¼ í‰ê°€í•©ë‹ˆë‹¤. 
- RBMì—ì„œ ìµœì†Œí™”ë˜ëŠ” ì–‘ì´ ì•„ë‹ˆë¼, epoch ë‹¹ rmseë¥¼ í”Œë¡œíŒ…í•˜ë©´ í•™ìŠµì´ ì–´ë–»ê²Œ ì§„í–‰ë˜ê³  í•˜ì´í¼ ë§¤ê°œ ë³€ìˆ˜ë¥¼ ì–´ë–»ê²Œ ì¡°ì •í•´ì•¼í•˜ëŠ”ì§€ì— ëŒ€í•œ ëŒ€ëµì ì¸ ì´í•´ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. 
- ì¼ë°˜ì ìœ¼ë¡œ rmseê°€ í•™ìŠµ epochsì˜ í•¨ìˆ˜ë¡œ ë‹¨ì¡°ë¡­ê²Œ ê°ì†Œí•˜ëŠ” ê²ƒì„ ë³´ê³  ì‹¶ìŠµë‹ˆë‹¤. 
- ìë™í™”ëœ í•˜ì´í¼ íŒŒë¼ë¯¸í„° ìµœì í™” ë°©ë²•ì„ ì‚¬ìš©í•  ìˆ˜ëŠ” ìˆì§€ë§Œ, í•™ìŠµ í”„ë¡œì„¸ìŠ¤ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ê²€ì‚¬í•˜ëŠ” ë° ì‹œê°„ì„ í• ì• í•  ê²ƒì„ ê°•ë ¥íˆ ì œì•ˆí•©ë‹ˆë‹¤. 
- í•˜ì´í¼ íŒŒë¼ë¯¸í„°ì— ëŒ€í•´ ê¸°ëŒ€í•  ìˆ˜ ìˆëŠ” ê°’ ë²”ìœ„ì— ëŒ€í•œ ì•„ì´ë””ì–´ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ, ëŒ€ë¶€ë¶„ì˜ ìë™í™”ëœ í•˜ì´í¼ ë§¤ê°œ ë³€ìˆ˜ ê²€ìƒ‰ ë°©ë²•ì€ ê°ë… í•™ìŠµì— ìµœì í™”ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ê°ë…ë˜ì§€ ì•Šì€ ì‘ì—…ì—ë„ ì˜ ì‘ë™í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

- ë‘ ê°€ì§€ ìµœì¢… ì ìˆ˜ëŠ” ì°¨ì´ì ê³¼ í•¨ê»˜ ëª¨ë“  ì„¸íŠ¸ì—ì„œ í›ˆë ¨ / í…ŒìŠ¤íŠ¸ í‰ê·  ì •í™•ë„ì…ë‹ˆë‹¤. ì´ê²ƒì€ ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜ë˜ì—ˆìŠµë‹ˆë‹¤.


$$ AC = \frac{1}{m} \sum_{\mu=1}^{m} \sum_{i=1}^{N_v} \frac{1}{s_i} \, I(v=vp)_{\mu,i}, $$

- m = ì´ ì‚¬ìš©ì ìˆ˜, Nv = visible ë‹¨ìœ„ì˜ ì´ ìˆ˜,í–‰ ë‹¹ 0ì´ ì•„ë‹Œ ìš”ì†Œì˜ ìˆ˜, si = ì‚¬ìš©ì ë³„ ì´ ë“±ê¸‰ ìˆ˜
- ëª¨ë¸ì´ ì¼ë°˜í™”ë˜ê¸° ìœ„í•´ì„œëŠ” í›ˆë ¨ì™€ í…ŒìŠ¤íŠ¸ ì…‹ì˜ ì¸¡ì • ê¸°ì¤€ì˜ ì°¨ì´ê°€ ë„ˆë¬´ ì»¤ì„œëŠ” ì•ˆëœë‹¤ëŠ” ì ì„ ê¸°ì–µí•˜ë¼. ì˜¨ë¼ì¸ ë©”íŠ¸ë¦­ì„ ì‹œê°í™”í•˜ë ¤ë©´ RBM() ëª¨ë¸ í•¨ìˆ˜ì—ì„œ with_metrics = Trueë¥¼ ì„ íƒí•©ë‹ˆë‹¤. 
- ì¸¡ì • ê¸°ì¤€ì„ í‰ê°€í•  ë•Œ ëª¨í˜•ì€ ì‹¤í–‰í•˜ëŠ” ë° ì¡°ê¸ˆ ë” ì˜¤ë˜ ê±¸ë¦¬ì§€ë§Œ ì‘ì—…ì˜ íƒìƒ‰ ë‹¨ê³„ì—ì„œë§Œ ì‹¤í–‰í•´ì•¼ í•©ë‹ˆë‹¤

### 4.1.2 Model Evaluation

- ëª¨ë¸ ì„±ëŠ¥ì„ í‰ê°€í•˜ê³  ë¦¬í¬ì§€í† ë¦¬ì˜ ë‹¤ë¥¸ ì•Œê³ ë¦¬ì¦˜ê³¼ ë¹„êµí•˜ê¸° ìœ„í•´ recommend_k_items() ë°©ë²•ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. pandas ë°ì´í„° í”„ë ˆì„ í˜•ì‹ìœ¼ë¡œ ì˜¬ë°”ë¥¸ ì‚¬ìš©ì / í•­ëª© IDë¥¼ ë°˜í™˜í•˜ê¸° ìœ„í•´ 'maps'ì„ ë‘ ë²ˆì§¸ ì¸ìˆ˜ë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.


```python
#number of top score elements to be recommended  
K = 10

#Model prediction on the test set Xtst. 
top_k_1m, test_time =  model_1m.recommend_k_items(Xtst_1m)
```


```python
top_k_1m
```




    array([[0., 0., 0., ..., 0., 0., 0.],
           [0., 0., 0., ..., 0., 0., 0.],
           [0., 0., 0., ..., 0., 0., 0.],
           ...,
           [0., 0., 0., ..., 0., 0., 0.],
           [0., 0., 0., ..., 0., 0., 0.],
           [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)




```python
test_time
```




    1.9036312103271484



- top_këŠ” ê°€ì¥ ë†’ì€ ì¶”ì²œ ì ìˆ˜ë¥¼ ê°€ì§„ ì²« ë²ˆì§¸ K ìš”ì†Œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. 
- ì—¬ê¸°ì„œ ì¶”ì²œ ì ìˆ˜ëŠ” ì˜ˆì¸¡ëœ ë“±ê¸‰ì— í™•ë¥ ì„ ê³±í•˜ì—¬ í‰ê°€ë©ë‹ˆë‹¤. ì•Œê³ ë¦¬ì¦˜ì´ ì¶œë ¥ì— ëŒ€í•´ ê°€ì§€ê³  ìˆëŠ” ì‹ ë¢° ë”°ë¼ì„œ ì˜ˆì¸¡ëœ ë“±ê¸‰ 5ë¥¼ ê°€ì§„ ë‘ í•­ëª©ì„ ëª¨ë‘ ê°€ì§€ê³  ìˆì§€ë§Œ í™•ë¥ ì´ 0.5ì´ê³  ë‹¤ë¥¸ í•­ëª©ì´ 0.9ì¸ ê²½ìš° í›„ìëŠ” ë” ê´€ë ¨ì´ ìˆëŠ” ê²ƒìœ¼ë¡œ ê°„ì£¼ë©ë‹ˆë‹¤. 
- ì˜ˆì¸¡ì„ ê²€ì‚¬í•˜ê³  ì´ ì €ì¥ì†Œì—ì„œ í‰ê°€ ë©”íŠ¸ë¦­ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ up_k ë° Xtstë¥¼ ëª¨ë‘ pandas ë°ì´í„° í”„ë ˆì„ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.


```python
top_k_df_1m = am1m.map_back_sparse(top_k_1m, kind = 'prediction')
test_df_1m = am1m.map_back_sparse(Xtst_1m, kind = 'ratings')
```


```python
top_k_df_1m[1:10]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>movieID</th>
      <th>prediction</th>
      <th>userID</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>4.999514</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1029</td>
      <td>4.996136</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2028</td>
      <td>4.991727</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2355</td>
      <td>4.996497</td>
      <td>1</td>
    </tr>
    <tr>
      <th>5</th>
      <td>1270</td>
      <td>4.996549</td>
      <td>1</td>
    </tr>
    <tr>
      <th>6</th>
      <td>271</td>
      <td>4.988898</td>
      <td>1</td>
    </tr>
    <tr>
      <th>7</th>
      <td>1324</td>
      <td>4.986278</td>
      <td>1</td>
    </tr>
    <tr>
      <th>8</th>
      <td>758</td>
      <td>4.984018</td>
      <td>1</td>
    </tr>
    <tr>
      <th>9</th>
      <td>584</td>
      <td>4.990669</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>




```python
test_df_1m[1:10]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>movieID</th>
      <th>rating</th>
      <th>userID</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>588</td>
      <td>4</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1836</td>
      <td>5</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>5</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1962</td>
      <td>4</td>
      <td>1</td>
    </tr>
    <tr>
      <th>5</th>
      <td>1029</td>
      <td>5</td>
      <td>1</td>
    </tr>
    <tr>
      <th>6</th>
      <td>2028</td>
      <td>5</td>
      <td>1</td>
    </tr>
    <tr>
      <th>7</th>
      <td>1961</td>
      <td>5</td>
      <td>1</td>
    </tr>
    <tr>
      <th>8</th>
      <td>2355</td>
      <td>5</td>
      <td>1</td>
    </tr>
    <tr>
      <th>9</th>
      <td>2321</td>
      <td>3</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>




```python
rating_1m= ranking_metrics(
    data_size = "mv 1m",
    data_true =test_df_1m,
    data_pred =top_k_df_1m,
    time_train=train_time,
    time_test =test_time,
    K =10)

rating_1m
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Dataset</th>
      <th>K</th>
      <th>MAP</th>
      <th>Precision@k</th>
      <th>Recall@k</th>
      <th>Test time (s)</th>
      <th>Train time (s)</th>
      <th>nDCG@k</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>mv 1m</td>
      <td>10</td>
      <td>0.279546</td>
      <td>0.590629</td>
      <td>0.320554</td>
      <td>1.903631</td>
      <td>48.519701</td>
      <td>0.691484</td>
    </tr>
  </tbody>
</table>
</div>



- ê³µì‹ì ìœ¼ë¡œ, ë¹„ìš© í•¨ìˆ˜ê°€ í‰í‰í•´ì§ˆ ë•Œê¹Œì§€ ëª¨ë¸ì„ í›ˆë ¨ì‹œì¼œì•¼ í•˜ì§€ë§Œ ì¢…ì¢… "early stopping"ì˜ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ìœ„ì˜ ì˜ˆì—ì„œ ìš°ë¦¬ëŠ” ì•Œê³ ë¦¬ì¦˜ì„ í›ˆë ¨ì‹œì¼œ ìƒìœ„ ìˆœìœ„ ë©”íŠ¸ë¦­ì„ ë‹¬ì„±í•˜ê¸°ë¡œ ê²°ì •í–ˆìŠµë‹ˆë‹¤. ë” ë¹ ë¥¸ ìµœì í™”ë„ ê°€ëŠ¥í•˜ì§€ë§Œ ìˆœìœ„ ì¸¡ì • ê¸°ì¤€ì€ ê°ì†Œí•©ë‹ˆë‹¤.

## 4.2 100k Dataset


```python
#100k
model_100k = RBM(hidden_units= 600, training_epoch = 30, minibatch_size= 60,keep_prob= 0.9, with_metrics = True)
```


```python
train_time = model_100k.fit(Xtr_100k, Xtst_100k)
```


![png](images/syleeie/2019-05-05/output_56_0.png)



```python
#Model prediction on the test set Xtst. 
top_k_100k, test_time =  model_100k.recommend_k_items(Xtst_100k)

#to df
top_k_df_100k = am100k.map_back_sparse(top_k_100k, kind = 'prediction')
test_df_100k = am100k.map_back_sparse(Xtst_100k, kind = 'ratings')
```

### 4.2.1 Model evaluation 


```python
eval_100k= ranking_metrics(
    data_size = "mv 100k",
    data_true =test_df_100k,
    data_pred =top_k_df_100k,
    time_train=train_time,
    time_test =test_time,
    K=10) 

eval_100k
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Dataset</th>
      <th>K</th>
      <th>MAP</th>
      <th>Precision@k</th>
      <th>Recall@k</th>
      <th>Test time (s)</th>
      <th>Train time (s)</th>
      <th>nDCG@k</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>mv 100k</td>
      <td>10</td>
      <td>0.167566</td>
      <td>0.421527</td>
      <td>0.249489</td>
      <td>0.281705</td>
      <td>7.322173</td>
      <td>0.491173</td>
    </tr>
  </tbody>
</table>
</div>




```python

```
